在我们的系统里，本质上Skill 是一种自然语言接口的、并具有内置思考和智能能力的功能函数。

# Skill 函数的自我描述
Skill 函数对外提供自然语言的描述，这是做什么的，需要提供些什么输入。Skill可以动态的挂载给Agent（挂载了某个技能的Agent就有了这个能力，非常符合直觉，也非常灵活。 Agent可以共享一些基本的Skill，也可以完全不同）。同时Agent的system prompt会动态的被注入，告诉Agent有哪些skill存在（和function/tool的思想是类似的）。但是完全不需要操心JSON，因为我们希望Agent调用LLM的时候，不去花注意力（以及token)在JSON格式上，专注于解决要做的事情和问题。大模型的智能，会让他自然的在正确的时候选择用什么skill。这里有一些prompt engineering，但是完全不需要特别具体和细节，只要告诉LLM，有哪些skill（他们带着自我描述），LLM会自己选择合适的skill。

Agent看到的是，我能做什么，不需要知道具体怎么做的。

# Skill 的调用过程

* （大脑）LLM 发出一个自然语言的动作指令，指向某个`skill`，其他参数（即这个动作的意图）都是以自然语言的形式给出的。
* （小脑）(也是LLM)，去理解这个动作指令，并map 到具体 `skill`, 并且把大脑的意图参数，转换成`skill`python 函数需要的参数。即把自然语言，翻译映射到 python 函数的参数上。—— 因为这个过程需要的智力不高，所以可以用比较便宜的LLM 来完成。这也是唯一需要输出JSON的场景，因为机器代码只能识别机器语言，从自然语言到机器语言的转换，需要一次JSON 的映射。其他绝大部分信息交互，都是可以完全只用自然语言的。
*  (肌肉系统）Python程序体，得到要执行的skill和参数列表，调用具体的 skill 函数。
* 比一般设计的健壮性： 小脑和大脑都是有智能的。当小脑无法完成翻译工作（可能大脑输出有问题，参数不足，不具体等等），小脑会再去询问大脑：这个参数到底写什么，你这个什么意思，等等。大脑会根据上下文，给出合理的解释和补充。让小脑可以完成翻译。这个设计唯一缺点是更多的Token消耗。因为可能产生多轮对话。但是长期来看token会便宜的，而且质量和健壮性是第一位的。基本沟通下来，不会有搞不定的函数调用。比强制大脑输出JSON要好很多。一方面更健壮，不会有各种格式错误，第二，避免了大脑把注意力放在JSON格式上（虽然没有量化证据，但这很可能是对大脑发挥智能是更好的）
* 进一步兜底：参数正确的函数调用，仍然可能失败。这个失败同样由（小脑）向（大脑）反馈，即大脑可以得到一个动作失败的结果。基本上这就是大模型智能体的try and catch 的过程。


# Skill 函数的内部
Skill 函数也是一个python函数。它可以完全没智能。例如`查看文件` skill。但也可以包装比较复杂的智能过程。例如`研究某个信息`,可能包装了从理解问题、到自动化话搜索、到理解页面、提取信息的过程。
