import asyncio
import time
import os,json,textwrap
import re
import sqlite3
from typing import List, Set, Dict, Optional, Any, Deque
from collections import deque
from enum import Enum, auto
from dataclasses import dataclass, field
from core.browser.google import search_google
from core.browser.bing import search_bing

# å¼•å…¥ä¹‹å‰çš„ Adapter å®šä¹‰ (å‡è®¾åœ¨ drission_page_adapter æˆ– browser_adapter ä¸­)
from core.browser.browser_adapter import (
    BrowserAdapter, TabHandle, PageElement, InteractionReport, PageSnapshot, PageType
)
# å¼•å…¥å…·ä½“çš„ Adapter å®ç°
from core.browser.drission_page_adapter import DrissionPageAdapter
from core.action import register_action
from slugify import slugify

search_func = search_google

# ==========================================
# 1. çŠ¶æ€ä¸ä¸Šä¸‹æ–‡å®šä¹‰ (State & Context)
# ==========================================

class ContentVerdict(Enum):
    """Phase 3: é¡µé¢ä»·å€¼åˆ¤æ–­ç»“æœ"""
    TRASH = auto()              # åƒåœ¾/æ— å…³/ç™»å½•å¢™ -> å…³æ‰æˆ–è·³è¿‡
    RELEVANT_INDEX = auto()     # ç´¢å¼•é¡µ/åˆ—è¡¨é¡µ -> ä¸å€¼å¾—æ€»ç»“ï¼Œä½†å€¼å¾—æŒ–æ˜é“¾æ¥
    HIGH_VALUE = auto()         # é«˜ä»·å€¼å†…å®¹ -> æ€»ç»“å¹¶ä¿å­˜

@dataclass
class MissionContext:
    """
    å…¨å±€ä»»åŠ¡ä¸Šä¸‹æ–‡ (Global Memory)
    è·¨è¶Šæ‰€æœ‰é€’å½’å±‚çº§å…±äº«çš„æ•°æ®ã€‚
    """
    purpose: str
    save_dir: str
    deadline: float

    # å†å²è®°å½• (å»é‡ç”¨)
    visited_urls: Set[str] = field(default_factory=set)
    interaction_history: Set[str] = field(default_factory=set) # "URL|ButtonText"

    # å·²è¯„ä¼°è¿‡çš„é“¾æ¥å’ŒæŒ‰é’®ï¼ˆé¿å…é‡å¤è°ƒç”¨ LLMï¼‰
    assessed_links: Set[str] = field(default_factory=set)
    assessed_buttons: Set[str] = field(default_factory=set)  # "URL|ButtonText"

    # æˆæœåº“
    knowledge_base: List[Dict] = field(default_factory=list)

    # é»‘åå• (ä¸å¯é…ç½®çš„ç¡¬è§„åˆ™)
    blacklist: Set[str] = field(default_factory=lambda: {
        "facebook.com", "twitter.com", "instagram.com", "taobao.com",
        "jd.com", "amazon.com", "signin", "login", "signup"
    })

    # SQLite æ•°æ®åº“è¿æ¥
    _db_conn: Optional[sqlite3.Connection] = field(default=None, init=False, repr=False)

    def __post_init__(self):
        """åˆå§‹åŒ–åè‡ªåŠ¨è°ƒç”¨ï¼Œè®¾ç½® SQLite æ•°æ®åº“"""
        self._init_database()
        self._load_assessed_history()

    def _init_database(self):
        """åˆå§‹åŒ– SQLite æ•°æ®åº“"""
        db_path = os.path.join(self.save_dir, ".crawler_assessment.db")
        self._db_conn = sqlite3.connect(db_path)
        self._db_conn.execute("PRAGMA journal_mode=WAL")  # æå‡å¹¶å‘æ€§èƒ½

        # åˆ›å»ºè¡¨
        self._db_conn.execute("""
            CREATE TABLE IF NOT EXISTS assessed_links (
                url TEXT PRIMARY KEY,
                assessed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        self._db_conn.execute("""
            CREATE TABLE IF NOT EXISTS assessed_buttons (
                button_key TEXT PRIMARY KEY,
                assessed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        self._db_conn.commit()

    def _load_assessed_history(self):
        """ä»æ•°æ®åº“åŠ è½½å·²è¯„ä¼°å†å²åˆ°å†…å­˜"""
        # åŠ è½½å·²è¯„ä¼°çš„é“¾æ¥
        cursor = self._db_conn.execute("SELECT url FROM assessed_links")
        self.assessed_links = {row[0] for row in cursor}

        # åŠ è½½å·²è¯„ä¼°çš„æŒ‰é’®
        cursor = self._db_conn.execute("SELECT button_key FROM assessed_buttons")
        self.assessed_buttons = {row[0] for row in cursor}

    def is_time_up(self) -> bool:
        return time.time() > self.deadline

    def mark_visited(self, url: str):
        self.visited_urls.add(url)

    def has_visited(self, url: str) -> bool:
        # ç®€å•å»é™¤æœ«å°¾æ–œæ å’Œå‚æ•°è¿›è¡Œæ¯”è¾ƒå¯èƒ½æ›´ç¨³å¥ï¼Œè¿™é‡Œå…ˆåšç²¾ç¡®åŒ¹é…
        return url in self.visited_urls

    def mark_interacted(self, url: str, button_text: str):
        key = f"{url}|{button_text}"
        self.interaction_history.add(key)

    def has_interacted(self, url: str, button_text: str) -> bool:
        key = f"{url}|{button_text}"
        return key in self.interaction_history

    def mark_link_assessed(self, url: str):
        """æ ‡è®°é“¾æ¥ä¸ºå·²è¯„ä¼°"""
        if url not in self.assessed_links:
            self.assessed_links.add(url)
            self._db_conn.execute(
                "INSERT OR IGNORE INTO assessed_links (url) VALUES (?)",
                (url,)
            )
            self._db_conn.commit()

    def has_link_assessed(self, url: str) -> bool:
        """æ£€æŸ¥é“¾æ¥æ˜¯å¦å·²è¯„ä¼°è¿‡"""
        return url in self.assessed_links

    def mark_buttons_assessed(self, url: str, button_texts: List[str]):
        """æ‰¹é‡æ ‡è®°æŒ‰é’®ä¸ºå·²è¯„ä¼°"""
        timestamp = time.time()
        for button_text in button_texts:
            key = f"{url}|{button_text}"
            if key not in self.assessed_buttons:
                self.assessed_buttons.add(key)
                self._db_conn.execute(
                    "INSERT OR IGNORE INTO assessed_buttons (button_key) VALUES (?)",
                    (key,)
                )
        self._db_conn.commit()

    def has_button_assessed(self, url: str, button_text: str) -> bool:
        """æ£€æŸ¥æŒ‰é’®æ˜¯å¦å·²è¯„ä¼°è¿‡"""
        key = f"{url}|{button_text}"
        return key in self.assessed_buttons

    def cleanup(self):
        """æ¸…ç†èµ„æºï¼Œå…³é—­æ•°æ®åº“è¿æ¥"""
        if self._db_conn:
            self._db_conn.close()
            self._db_conn = None


@dataclass
class TabSession:
    """
    ç‰©ç†æ ‡ç­¾é¡µä¸Šä¸‹æ–‡ (Physical Tab Context)
    """
    handle: TabHandle
    current_url: str = ""
    depth: int = 0
    # å¾…è®¿é—®é“¾æ¥é˜Ÿåˆ— (FIFO)
    # å­˜å‚¨çš„æ˜¯çº¯ URLï¼Œå½“å½“å‰é¡µé¢äº¤äº’åšå®Œäº†ï¼Œå°±ä»è¿™é‡Œ pop
    pending_link_queue: Deque[str] = field(default_factory=deque) 


# ==========================================
# 2. é€»è¾‘æ ¸å¿ƒ (Logic Mixin)
# ==========================================

class DigitalInternCrawlerMixin:
    """
    æ•°å­—å®ä¹ ç”Ÿé€»è¾‘æ ¸å¿ƒã€‚
    å®ç°äº† "Observation -> Thought -> Action" çš„é€’å½’å¾ªç¯ã€‚
    """

    # ä¾èµ–æ³¨å…¥ï¼šå‡è®¾ self.cerebellum å’Œ self.logger å·²ç»ç”±ä¸»ç±»æä¾›
    
    
        

    #def start_browser(self, ctx: MissionContext):
    #    profile_path = os.path.join(self.workspace_root ,".matrix", "browser_profile", self.name)
    #    download_path = os.path.join(self.workspace_root ,"download")
    #    self.browser_adapter = DrissionPageAdapter(
    #        profile_path=profile_path,
    #        download_path=download_path
    #    )

    def sanitize_filename(self, name: str, max_length: int = 200) -> str:
        """
        æ¸…æ´—å­—ç¬¦ä¸²ï¼Œä½¿å…¶å¯ä»¥ä½œä¸ºåˆæ³•çš„æ–‡ä»¶å/ç›®å½•åï¼ŒåŒæ—¶ä¿ç•™ä¸­æ–‡ã€‚
        
        è§„åˆ™:
        1. å»é™¤ Windows/Linux éæ³•å­—ç¬¦
        2. å»é™¤ä¸å¯è§å­—ç¬¦ (æ¢è¡Œã€Tabç­‰)
        3. å»é™¤é¦–å°¾çš„ç©ºæ ¼å’Œç‚¹ (Windows ä¸å–œæ¬¢æ–‡ä»¶åä»¥ç‚¹æˆ–ç©ºæ ¼ç»“å°¾)
        4. æˆªæ–­é•¿åº¦ï¼Œé˜²æ­¢è·¯å¾„è¿‡é•¿
        """
        if not name:
            return "untitled"

        # 1. æ›¿æ¢æ–‡ä»¶ç³»ç»Ÿéæ³•å­—ç¬¦ä¸ºä¸‹åˆ’çº¿
        # Windowséæ³•å­—ç¬¦: < > : " / \ | ? *
        name = re.sub(r'[<>:"/\\|?*]', '_', name)

        # 2. æ›¿æ¢ä¸å¯è§æ§åˆ¶å­—ç¬¦ (å¦‚æ¢è¡Œç¬¦ \n, \r, \t) ä¸ºç©ºæ ¼
        name = "".join(ch if ch.isprintable() else " " for ch in name)

        # 3. å°†è¿ç»­çš„ç©ºæ ¼æˆ–ä¸‹åˆ’çº¿åˆå¹¶ä¸ºä¸€ä¸ª (ç¾è§‚ä¼˜åŒ–)
        name = re.sub(r'[\s_]+', '_', name)

        # 4. å»é™¤é¦–å°¾çš„ç©ºæ ¼å’Œç‚¹ (Windowsæ–‡ä»¶åä¸èƒ½ä»¥ç‚¹ç»“å°¾)
        name = name.strip(' .')

        # 5. å¦‚æœæ¸…æ´—åä¸ºç©º (æ¯”å¦‚åŸæ–‡ä»¶åå…¨æ˜¯éæ³•å­—ç¬¦)ï¼Œç»™ä¸ªé»˜è®¤å€¼
        if not name:
            name = "untitled_file"

        # 6. æˆªæ–­é•¿åº¦ (é€šå¸¸æ–‡ä»¶ç³»ç»Ÿé™åˆ¶ 255 å­—èŠ‚ï¼Œè€ƒè™‘åˆ°è·¯å¾„é•¿åº¦ï¼Œé™åˆ¶åœ¨ 200 å­—ç¬¦æ¯”è¾ƒå®‰å…¨)
        return name[:max_length]



    @register_action(
        "ä¸Šç½‘æœç´¢å¹¶ä¸‹è½½èµ„æ–™",
        param_infos={
            "purpose": "ç ”ç©¶çš„å…·ä½“ç›®æ ‡",
            "search_phrase": "åœ¨æœç´¢å¼•æ“è¾“å…¥çš„åˆå§‹å…³é”®è¯",
            "topic": "ä¿å­˜èµ„æ–™çš„æ–‡ä»¶å¤¹åç§°",
            "max_time": "æœ€å¤§è¿è¡Œæ—¶é—´(åˆ†é’Ÿ)"
        }
    )
    async def research_crawler(self, purpose: str, search_phrase: str, topic: str, max_time: int = 30):
        """
        [Entry Point] å¤–éƒ¨è°ƒç”¨çš„å…¥å£
        """
        # 1. å‡†å¤‡ç¯å¢ƒ
        save_dir = os.path.join(self.workspace_root, "downloads", self.sanitize_filename(topic))

        os.makedirs(save_dir, exist_ok=True)

        profile_path = os.path.join(self.workspace_root ,".matrix", "browser_profile", self.name)
        
        self.browser_adapter = DrissionPageAdapter(
            profile_path=profile_path,
            download_path=save_dir
        )
        
        ctx = MissionContext(
            purpose=purpose,
            save_dir=save_dir,
            deadline=time.time() + int(max_time) * 60
        )
        
        self.logger.info(f"ğŸš€ Mission Start: {purpose}")
        
        # 2. å¯åŠ¨æµè§ˆå™¨
        await self.browser_adapter.start(headless=False) # è°ƒè¯•æ¨¡å¼å…ˆå¼€æœ‰å¤´
        
        try:
            # 3. åˆå§‹é˜¶æ®µï¼šæ‰§è¡Œæœç´¢ (Phase 0)
            # æˆ‘ä»¬æŠŠæœç´¢ç»“æœé¡µå½“åšç¬¬ä¸€ä¸ª Tab çš„åˆå§‹é¡µé¢
            first_tab = await self.browser_adapter.get_tab()
            
            search_result = await search_func(self.browser_adapter, first_tab, search_phrase)
            # åˆ›å»ºåˆå§‹ Session
            initial_session = TabSession(handle=first_tab, current_url="")
            # æŠŠæœç´¢é¡µç›´æ¥æ¨å…¥é˜Ÿåˆ—ï¼Œè®© lifecycle å»å¤„ç† navigate
            for result in search_result:
                initial_session.pending_link_queue.append(result['url'])

            
            
            
            
            
            
            # 4. è¿›å…¥é€’å½’å¾ªç¯
            await self._run_tab_lifecycle(initial_session, ctx)
            
            # 5. ç”ŸæˆæŠ¥å‘Š
            return self._generate_final_report(ctx)

        except Exception as e:
            self.logger.exception("Crawler crashed")
            return f"Mission failed with error: {e}"
        finally:
            self.logger.info("ğŸ›‘ Closing browser...")
            await self.browser_adapter.close()
            ctx.cleanup()  # å…³é—­æ•°æ®åº“è¿æ¥

    async def _run_tab_lifecycle(self, session: TabSession, ctx: MissionContext):
        """
        [The Core Loop] ç‰©ç† Tab çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€‚
        åªè¦é˜Ÿåˆ—ä¸ç©ºï¼Œæˆ–è€…é¡µé¢ä¸Šæœ‰äº¤äº’è¦åšï¼Œå°±ä¸€ç›´åœ¨è¿™è½¬ã€‚
        """
        
        while not ctx.is_time_up():
            
            # --- Phase 1: Navigation (ä»é˜Ÿåˆ—å–ä»»åŠ¡) ---
            # å¦‚æœå½“å‰æ²¡æœ‰åœ¨æµè§ˆç‰¹å®šé¡µé¢ï¼Œæˆ–è€…å½“å‰é¡µé¢çš„äº¤äº’éƒ½å¤„ç†å®Œäº†ï¼ˆFlagï¼‰ï¼Œåˆ™ä»é˜Ÿåˆ—å–ä¸‹ä¸€ä¸ª
            if not session.pending_link_queue:
                self.logger.info(f"Tab {session.handle} queue empty. Closing tab.")
                break # é˜Ÿåˆ—ç©ºäº†ï¼Œç»“æŸè¿™ä¸ª Tab
                
            next_url = session.pending_link_queue.popleft()
            print(next_url)
            
            # 1.1 é—¨ç¦æ£€æŸ¥
            if ctx.has_visited(next_url) or any(bl in next_url for bl in ctx.blacklist):
                continue
            
            self.logger.info(f"ğŸ”— Navigating to: {next_url}")
            nav_report = await self.browser_adapter.navigate(session.handle, next_url)
            final_url =  self.browser_adapter.get_tab_url(session.handle)
            session.current_url = final_url # æ›´æ–°å½“å‰

            # 1.2 æ ‡è®°å·²è®¿é—®    
            ctx.mark_visited(next_url)
            ctx.mark_visited(final_url)
            self.logger.info(f"ğŸ”— Landed on: {final_url}")
            # 2. äºŒæ¬¡é»‘åå•æ£€æŸ¥ (é˜²æ­¢è·³è½¬åˆ° Facebook/Login é¡µ)
            if any(bl in final_url for bl in ctx.blacklist):
                self.logger.warning(f"ğŸš« Redirected to blacklisted URL: {final_url}. Aborting tab.")
                # è¿™ç§æƒ…å†µä¸‹ï¼Œç›´æ¥ break è¿˜æ˜¯ continue?
                # è¿™æ˜¯ä¸€ä¸ª Dead Endï¼Œæ‰€ä»¥åº”è¯¥ç»“æŸå½“å‰é¡µé¢çš„å¤„ç†ï¼Œå»å¤„ç†é˜Ÿåˆ—é‡Œçš„ä¸‹ä¸€ä¸ª
                continue 

            # === Phase 2: Identify Logic Branch ===
            # å…ˆç¨³ä¸€æ‰‹ï¼Œä¸ç”¨å…¨é¡µé¢ stabilizeï¼Œåªè¦èƒ½æ‹¿åˆ° contentType å°±è¡Œ
            page_type = await self.browser_adapter.analyze_page_type(session.handle)

            if page_type == PageType.ERRO_PAGE:
                self.logger.warning(f"ğŸš« Error Page: {final_url}. Skipping.")
                continue

            # === åˆ†æ”¯ A: é™æ€èµ„æº (Dead End) ===
            if page_type == PageType.STATIC_ASSET:
                self.logger.info(f"ğŸ“„ Detected Static Asset: {session.current_url}")
                
                # 1. å°è¯•è·å–å†…å®¹ (Snapshot)
                #    å¯¹äº PDFï¼Œå¦‚æœæµè§ˆå™¨èƒ½æå–æ–‡å­—æœ€å¥½ï¼Œæå–ä¸åˆ°å°±æ‹¿æ–‡ä»¶åå’Œ URL åšæ‘˜è¦
                snapshot = await self.browser_adapter.get_page_snapshot(session.handle)
                
                # 2. å°è„‘åˆ¤æ–­ (Assess)
                #    "è¿™æ˜¯ä¸€ä¸ª PDFï¼Œæ ‡é¢˜æ˜¯ xxxï¼Œå‰ 500 å­—æ˜¯ xxx... å€¼å¾—å­˜å—ï¼Ÿ"
                #    æ³¨æ„ï¼šå¯¹äºæ— æ³•æå–æ–‡å­—çš„ Image/PDFï¼Œåªèƒ½è®©å°è„‘æ ¹æ® URL/Title ç›²çŒœ
                verdict_dict = await self._assess_page_value(snapshot, ctx)
                verdict = verdict_dict["verdict"]
                
                if verdict == ContentVerdict.HIGH_VALUE:
                    self.logger.info("ğŸ’¾ Saving Asset...")
                    # ä¿å­˜æ–‡ä»¶
                    await self.browser_adapter.save_static_asset(session.handle)
                    # è®°å½•åˆ° Context
                    ctx.knowledge_base.append({"type": "file", "url": session.current_url, "title": snapshot.title})
                
                # 3. ç»“æŸå½“å‰ URL çš„å¤„ç†
                #    å› ä¸ºæ˜¯ Static Assetï¼Œæ²¡æœ‰äº¤äº’ï¼Œæ²¡æœ‰ scoutï¼Œç›´æ¥ break (å¦‚æœæ˜¯å•é¡µ) æˆ– continue (å¦‚æœè¿˜è¦å¤„ç†é˜Ÿåˆ—)
                #    ä½†åœ¨æˆ‘ä»¬çš„é€»è¾‘é‡Œï¼ŒAsset æ˜¯ç»ˆç‚¹ï¼Œå¤„ç†å®Œå°±å¯ä»¥ä» Queue å–ä¸‹ä¸€ä¸ªäº†
                #    ä¸éœ€è¦ break Loop (Loop æ˜¯å¤„ç† Queue çš„)ï¼Œè€Œæ˜¯ continue Outer Loop
                continue 


            # === åˆ†æ”¯ B: äº¤äº’å¼ç½‘é¡µ (Infinite Possibilities) ===
            elif page_type == PageType.NAVIGABLE:
                
                # è¿›å…¥æˆ‘ä»¬ä¹‹å‰çš„å¤æ‚å¾ªç¯ï¼šStabilize -> Assess -> Scout -> Act
                # è¿™é‡Œå°±æ˜¯åŸæ¥çš„ Inner Loop ä»£ç 
                self.logger.debug("ğŸŒ Detected Navigable Page. Entering complex loop.")
                page_active = True
                page_changed = True
                one_line_summary=""
                while page_active and not ctx.is_time_up():
                    # 1. Stabilize (æ»šåŠ¨åŠ è½½)
                    
                    
                    if page_changed: 
                        #ç¬¬ä¸€æ¬¡æ°¸è¿œæ˜¯page_changedï¼Œä½†å¦‚æœç‚¹è¿‡ä¸€ä¸ªbuttonæ²¡ä»€ä¹ˆå˜åŒ–ï¼Œä»å¤´å†æ¥ä¸€æ¬¡ï¼Œå°±æ˜¯Falseäº†
                        #è¿™æ—¶å€™ä¸éœ€è¦å†å»stablize,ä¹Ÿä¸ç”¨å†çœ‹assessäº†ï¼Œç›´æ¥çœ‹scout
                        await self.browser_adapter.stabilize(session.handle)
                        # 2. Assess (HTML Extract -> Brain)
                        snapshot = await self.browser_adapter.get_page_snapshot(session.handle)
                        verdict_dict = await self._assess_page_value(snapshot, ctx)
                        verdict = verdict_dict["verdict"]
                        one_line_summary = verdict_dict["reason"]
                        
                        if verdict == ContentVerdict.HIGH_VALUE:
                            await self._save_content(snapshot, ctx) # ä¿å­˜ Summary
                        elif verdict == ContentVerdict.TRASH:
                            page_active = False; 
                            continue

                    # === Phase 4: Scouting (Look) ===
                    # æ‰«ææ‰€æœ‰å…ƒç´ 
                    links, buttons = await self.browser_adapter.scan_elements(session.handle)
                    #linksçš„æ ¼å¼ï¼š{url: text}
                    #buttonsçš„æ ¼å¼ï¼š{text: button_element}
                    self.logger.debug(f"ğŸ” Found {len(links)} links and {len(buttons)} buttons.")



                    # 4.1 å¤„ç† Links -> å…¥é˜Ÿ (ä¸ç«‹å³è®¿é—®)
                    # å¦‚æœpage_changed = Falseï¼Œè¿™ä¸ªå¯ä»¥è·³è¿‡äº†

                    if page_changed:
                        filtered_links = {}
                        for link in links:

                            # è¿‡æ»¤æ‰å·²è¯„ä¼°è¿‡çš„é“¾æ¥ï¼ˆé¿å…é‡å¤è°ƒç”¨ LLMï¼‰
                            if ctx.has_link_assessed(link):
                                continue
                            #å…ˆåˆ¤æ–­è¿™ä¸ªlinkæ˜¯å¦å·²ç»è®¿é—®è¿‡ï¼Œæˆ–è€…æ˜¯å¦åœ¨é»‘åå•ä¸­ï¼Œä»¥åŠæ˜¯ä¸æ˜¯å·²ç»åœ¨pending_link_queueé‡Œ
                            if ctx.has_visited(link):
                                continue
                            if link in session.pending_link_queue:
                                continue
                            if any(bl in link for bl in ctx.blacklist):
                                continue
                            
                            
                            filtered_links[link] = links[link]

                        selected_links = await self._filter_relevant_links(filtered_links,one_line_summary, ctx)

                        # è®°å½•æ‰€æœ‰è¯„ä¼°è¿‡çš„é“¾æ¥ï¼ˆæ— è®ºæ˜¯å¦è¢«é€‰ä¸­ï¼‰
                        for link in filtered_links:
                            ctx.mark_link_assessed(link)

                        new_links_count = 0
                        for link in selected_links:

                            session.pending_link_queue.append(link)
                            new_links_count += 1
                        self.logger.info(f"ğŸ‘€ Scouted {new_links_count} relevant links (enqueued).")

                    # 4.2 å¤„ç† Buttons -> å€™é€‰åˆ—è¡¨
                    candidate_buttons=[]
                    #åªä¿ç•™æ²¡è¯„ä¼°è¿‡çš„æŒ‰é’®
                    for button_text in buttons:
                        # è¿‡æ»¤æ‰å·²è¯„ä¼°è¿‡çš„æŒ‰é’®
                        if not ctx.has_button_assessed(session.current_url, button_text):
                            candidate_buttons.append({
                                button_text: buttons[button_text]
                            })
                

                    
                    # === Phase 5: Execution (Act) ===
                    # å°è¯•ç‚¹å‡»æœ€æœ‰ä»·å€¼çš„æŒ‰é’®
                    # å¦‚æœå°è„‘å†³å®šä¸ç‚¹ä»»ä½•æŒ‰é’®ï¼Œæˆ–è€…æ²¡æŒ‰é’®å¯ç‚¹ï¼ŒInner Loop ç»“æŸ
                    if not candidate_buttons:
                        self.logger.info("ğŸ¤” No worthy interactions found. Moving to next page in queue.")
                        page_active = False # ç»“æŸå½“å‰é¡µ
                        continue

                    chosen_button = await self._choose_best_interaction(candidate_buttons,one_line_summary, ctx)

                    # è®°å½•æ‰€æœ‰è¯„ä¼°è¿‡çš„æŒ‰é’®ï¼ˆæ— è®ºæ˜¯å¦è¢«é€‰ä¸­ï¼‰
                    assessed_button_texts = [list(btn.keys())[0] for btn in candidate_buttons]
                    ctx.mark_buttons_assessed(session.current_url, assessed_button_texts)

                    if not chosen_button:
                        self.logger.info("ğŸ¤” No worthy interactions found. Moving to next page in queue.")
                        page_active = False # ç»“æŸå½“å‰é¡µ
                        continue
                    
                    # æ‰§è¡Œç‚¹å‡»
                    self.logger.info(f"point_up: Clicking button: [{chosen_button.get_text()}]")
                    ctx.mark_interacted(session.current_url, chosen_button.get_text())
                    
                    report = await self.browser_adapter.click_and_observe(session.handle, chosen_button)
                    
                    # 5.1 å¤„ç†åæœ: æ–° Tab
                    if report.new_tabs:
                        self.logger.info(f"âœ¨ New Tab(s) detected: {len(report.new_tabs)}")
                        for new_tab_handle in report.new_tabs:
                            # é€’å½’ï¼åˆ›å»ºæ–°çš„ Session
                            new_session = TabSession(handle=new_tab_handle, current_url="", depth=session.depth + 1)
                            # ç­‰å¾…é€’å½’è¿”å›
                            await self._run_tab_lifecycle(new_session, ctx)
                            # é€’å½’å›æ¥åï¼Œå…³é—­é‚£ä¸ª tab (é€šå¸¸ lifecycle ç»“æŸæ—¶ä¼šè‡ªæ€ï¼Œè¿™é‡Œå¯ä»¥åšä¸ªä¿é™©)
                            await self.browser_adapter.close_tab(new_tab_handle)
                    
                    # 5.2 å¤„ç†åæœ: é¡µé¢å˜åŠ¨ (Soft Restart)
                    if report.is_dom_changed or report.is_url_changed:
                        self.logger.info("ğŸ”„ Page mutated. Triggering Soft Restart (Re-assess).")
                        # ä¸è®¾ç½® page_active = Falseï¼Œè€Œæ˜¯ç›´æ¥ continue Inner Loop
                        # è¿™ä¼šå¯¼è‡´é‡æ–° Stabilize -> Assess -> Scout
                        # æ³¨æ„æ›´æ–° URL
                        page_changed = True
                        if report.is_url_changed:
                            session.current_url =  self.browser_adapter.get_tab_url(session.handle) # è·å–æœ€æ–° URL
                        continue 

                    # 5.3 å¤„ç†åæœ: æ— äº‹å‘ç”Ÿæˆ–ä»…ä¸‹è½½
                    # å¦‚æœæ²¡å˜åŠ¨ï¼Œä¹Ÿæ²¡å¼¹çª—ï¼Œæˆ‘ä»¬å‡è®¾è¿™ä¸ªæŒ‰é’®ç‚¹å®Œäº†ã€‚
                    # ç»§ç»­ Inner Loop çš„ä¸‹ä¸€æ¬¡è¿­ä»£ï¼Ÿä¸ï¼Œå› ä¸º DOM æ²¡å˜ï¼Œcandidate_buttons ä¹Ÿæ²¡å˜ã€‚
                    # æˆ‘ä»¬åº”è¯¥ç»§ç»­ä» candidate_buttons é‡Œé€‰ä¸‹ä¸€ä¸ªå—ï¼Ÿ
                    # ä¸ºäº†ç®€å•èµ·è§ï¼Œå¦‚æœç‚¹äº†ä¸€ä¸ªæŒ‰é’®æ²¡ååº”ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºâ€œè¿™é¡µæ²¡å•¥å¥½ç‚¹çš„äº†â€ï¼Œæˆ–è€…è®©å°è„‘åœ¨ä¸‹ä¸€è½®é‡æ–°é€‰ï¼ˆåæ­£å·²ç» mark interacted äº†ï¼‰
                    # è¿™é‡Œé€‰æ‹©ï¼šç»§ç»­å¾ªç¯ï¼Œè®© Assess/Scout å†è·‘ä¸€éï¼ˆæˆæœ¬ä¸é«˜ï¼‰ï¼Œç¡®ä¿ä¸‡æ— ä¸€å¤±
                    page_changed = False
                    continue

            
            # End Inner Loop
        
        # End Outer Loop (Queue Empty or Time Up)
        self.logger.info(f"ğŸ Tab Session ended. visited: {len(ctx.visited_urls)}")
        # è¿™é‡Œçš„ close_tab äº¤ç»™è°ƒç”¨æ–¹å¤„ç†ï¼Œæˆ–è€… adapter.close_tab(session.handle)


    # ==========================================
    # 3. å°è„‘å†³ç­–è¾…åŠ© (Brain Power)
    # ==========================================

    async def _assess_page_value(self, snapshot: PageSnapshot, ctx: MissionContext):
        """
        [Brain] è¯„ä¼°é¡µé¢ä»·å€¼ã€‚
        è¾“å…¥ï¼šé¡µé¢å¿«ç…§ (URL, Title, Text Preview)
        è¾“å‡ºï¼šContentVerdict (TRASH | RELEVANT_INDEX | HIGH_VALUE)
        """
        
        # 1. æç®€å¯å‘å¼è¿‡æ»¤ (Heuristics)
        # å¦‚æœæ˜¯ NAVIGABLE ç±»å‹ï¼Œä¸”å†…å®¹æçŸ­ (ä¾‹å¦‚ < 50 å­—ç¬¦)ï¼Œ
        # å¾€å¾€æ˜¯è„šæœ¬æ²¡åŠ è½½å‡ºæ¥ï¼Œæˆ–è€…ç¡®å®æ˜¯ç©ºé¡µã€‚
        # ä¸ºäº†é˜²æ­¢æ¼æ‰åªæœ‰å›¾ç‰‡çš„é¡µé¢ï¼Œæˆ‘ä»¬ç¨å¾®å®½å®¹ä¸€ç‚¹ï¼Œäº¤ç»™ LLMï¼Œ
        # ä½†å¦‚æœè¿ Title éƒ½æ˜¯ç©ºçš„ï¼Œç›´æ¥æ‰”æ‰ã€‚
        if not snapshot.title and len(snapshot.main_text) < 10:
            self.logger.warning(f"ğŸ—‘ï¸ Empty title and content: {snapshot.url}")
            return {"verdict":ContentVerdict.TRASH, "reason":"Empty title and content"}

        # 2. æ„é€  Prompt
        # æˆªæ–­æ–‡æœ¬ï¼Œé¿å… Token æº¢å‡ºã€‚2000å­—é€šå¸¸è¶³å¤Ÿåˆ¤æ–­ä»·å€¼ã€‚
        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œmain_text å¯èƒ½æ˜¯ç©ºçš„æˆ–è€…åªæœ‰å…ƒæ•°æ®ï¼Œæ²¡å…³ç³»ã€‚
        preview_text = snapshot.main_text[:2500]
        
        # é’ˆå¯¹é™æ€èµ„æºå’Œæ™®é€šç½‘é¡µä½¿ç”¨ç•¥å¾®ä¸åŒçš„ Prompt ä¾§é‡
        if snapshot.content_type == PageType.STATIC_ASSET:
            evaluation_guide = textwrap.dedent("""
            Type: STATIC FILE (PDF/Image/Doc).
            Task: Decide if this file is relevant to [Research Goal] and should be DOWNLOADED based on its Title and URL.
            Allowed Verdict Value:
            - TRASH: Completely unrelated.
            - HIGH_VALUE: The file seems relevant to the Research Goal (e.g., specific data, report, paper) or not enough information to judge. (Download anyway.)
            
            (Note: Use HIGH_VALUE if you are not sure.)
            """)
        else:
            evaluation_guide = textwrap.dedent("""
            Type: WEBPAGE.
            Task: Analyze content relevance.
            Allowed Verdict Value:
            - TRASH: 
                * Login/Signup walls, Captchas.
                * 404/Errors, "Site under construction".
                * Pure SEO spam, generic ads, "Buy now" product pages (unless research goal is shopping).
                * Completely off-topic content.
            - RELEVANT_INDEX: 
                * Hub pages, Directories, List of links (e.g., "Top 10 resources").
                * Content is relevant but short/shallow (not worth summarizing, but worth exploring links).
                * If unsure or info is sparse but looks relevant -> Choose THIS.
            - HIGH_VALUE: 
                * Detailed articles, Reports, Data tables, Technical documentation.
                * Directly answers the Research Goal with substance.
            """)

        prompt = textwrap.dedent(f"""
        You are a Research Assistant.
        
        [Research Goal]
        "{ctx.purpose}"

        [Target Info]
        URL: {snapshot.url}
        Title: {snapshot.title}

        [Evaluation Guide]
        {evaluation_guide}

        [Content Preview]
        {preview_text}
        

        [Output Requirement]
        Return JSON ONLY. Format: {{"verdict": "one of allowed verdict values", "reason": "One line summary about the page"}}
        """)

        # 3. è°ƒç”¨å°è„‘
        try:
            # å‡è®¾ self.cerebellum.think è¿”å› dict: {'reply': '...', 'reasoning': '...'}
            # è¿™é‡Œçš„ messages æ ¼å¼å–å†³äºä½ çš„åº•å±‚ LLM æ¥å£ï¼Œè¿™é‡ŒæŒ‰å¸¸è§æ ¼å¼å†™
            response = await self.cerebellum.backend.think(
                messages=[{"role": "user", "content": prompt}]
            )
            raw_reasoning = response.get('reasoning', '').strip()
            raw_reply = response.get('reply', '').strip()
            #self.logger.debug(f"ğŸ§  Brain Reply: {raw_reply} \n\n Reasoning: {raw_reasoning}")
            
            # 4. è§£æç»“æœ
            # ç®€å•çš„ JSON æ¸…æ´—ï¼ˆé˜²æ­¢ LLM åŠ  markdown code blockï¼‰
            json_str = raw_reply.replace("```json", "").replace("```", "").strip()
            result = json.loads(json_str)
            
            verdict_str = result.get("verdict", "RELEVANT_INDEX").upper()
            reason = result.get("reason", "No reason provided")
            
            self.logger.info(f"ğŸ§  Brain Assess [{verdict_str}]: {snapshot.title[:30]}... | Reason: {reason}")

            if verdict_str == "HIGH_VALUE":
                return {"verdict": ContentVerdict.HIGH_VALUE, "reason": reason}
            elif verdict_str == "TRASH":
                return {"verdict": ContentVerdict.TRASH, "reason": reason}
            else:
                return {"verdict": ContentVerdict.RELEVANT_INDEX, "reason": snapshot.main_text[:800]}

        except Exception as e:
            self.logger.error(f"ğŸ§  Brain Assessment Failed: {e}. Defaulting to RELEVANT_INDEX.")
            # å‘ç”Ÿå¼‚å¸¸ï¼ˆå¦‚ JSON è§£æå¤±è´¥ã€ç½‘ç»œè¶…æ—¶ï¼‰æ—¶ï¼Œ
            # éµå¾ªâ€œé»˜è®¤å®½å®¹åŸåˆ™â€ï¼Œåªè¦ä¸æ˜¯é™æ€èµ„æºï¼Œå°±å½“ä½œ INDEX ç»§ç»­æ¢ç´¢ï¼Œé¿å…æ¼æ‰ã€‚
            if snapshot.content_type == PageType.STATIC_ASSET:
                # æ–‡ä»¶å¦‚æœåˆ¤æ–­ä¸å‡ºï¼Œé€šå¸¸ä¸ºäº†ä¿é™©èµ·è§ï¼Œå¯ä»¥è®¾ä¸º TRASH æˆ–è€… HIGH_VALUE
                # è¿™é‡Œä¸ºäº†é˜²æ­¢ä¸‹åƒåœ¾æ–‡ä»¶ï¼Œè®¾ä¸º TRASH (æˆ–è€…ä½ å¯ä»¥æ”¹ä¸º HIGH_VALUE)
                return {"verdict": ContentVerdict.HIGH_VALUE, "reason": "Static Asset"}
            return {"verdict": ContentVerdict.TRASH, "reason": "Possible related info"}

    async def _save_content(self, snapshot: PageSnapshot, ctx: MissionContext):
        """
        [Action] ä¿å­˜å†…å®¹åˆ°æ–‡ä»¶ç³»ç»Ÿã€‚
        ç­–ç•¥ï¼š
        1. çŸ­æ–‡ (< 1k chars): ç›´æ¥å­˜åŸæ–‡ï¼Œä¸æ€»ç»“ã€‚
        2. ä¸­æ–‡ (1k - 15k chars): å°è„‘è¿›è¡Œæ·±åº¦æ€»ç»“ (Deep Summary)ã€‚
        3. é•¿æ–‡ (> 15k chars): ç”Ÿæˆç®€ä»‹ (Abstract) + é™„ä¸Šå…¨æ–‡ã€‚
        """
        
        # === 1. æ–‡ä»¶åç”Ÿæˆç­–ç•¥ ===
        # ä½¿ç”¨ slugify ä¿è¯æ–‡ä»¶åå®‰å…¨ï¼Œæˆªæ–­é˜²æ­¢è¿‡é•¿
        safe_title = self.sanitize_filename(snapshot.title,60)
        # åŠ ä¸ªæ—¶é—´æˆ³é˜²æ­¢é‡åè¦†ç›– (æ¯”å¦‚ä¸¤ä¸ªé¡µé¢æ ‡é¢˜ä¸€æ ·)
        timestamp_suffix = str(int(time.time()))[-4:] 
        filename = f"{safe_title}_{timestamp_suffix}.md"
        save_path = os.path.join(ctx.save_dir, filename)

        text_len = len(snapshot.main_text)
        final_content = ""
        summary_type = ""

        # === 2. åˆ†çº§å¤„ç† ===

        # --- Tier A: çŸ­æ–‡ (ç›´æ¥ä¿å­˜) ---
        if text_len < 1000:
            self.logger.info(f"ğŸ’¾ Saving Short Content ({text_len} chars): {filename}")
            summary_type = "Raw (Short)"
            final_content = self._format_markdown(snapshot, "No summary generated (Content too short).", snapshot.main_text)

        # --- Tier B: ä¸­ç¯‡ (æ·±åº¦æ€»ç»“) ---
        elif text_len < 15000:
            self.logger.info(f"ğŸ“ Summarizing Medium Content ({text_len} chars)...")
            summary_type = "AI Summary"
            
            summary = await self._generate_summary(snapshot.main_text, ctx.purpose, mode="deep")
            final_content = self._format_markdown(snapshot, summary, snapshot.main_text)

        # --- Tier C: é•¿ç¯‡ (ç®€ä»‹ + åŸæ–‡) ---
        else:
            self.logger.info(f"ğŸ“š Archiving Long Content ({text_len} chars)...")
            summary_type = "Abstract + Full Text"
            
            # ç­–ç•¥ï¼šå–å‰ 5000 å­—ï¼ˆåŒ…å«ä»‹ç»ï¼‰å’Œå 2000 å­—ï¼ˆåŒ…å«ç»“è®ºï¼‰ï¼Œè·³è¿‡ä¸­é—´ç»†èŠ‚
            # è¿™æ ·å°è„‘èƒ½è¯»æ‡‚å¤§æ¦‚åœ¨è®²ä»€ä¹ˆï¼Œè€Œä¸ä¼šè¢«ä¸­é—´çš„ç»†èŠ‚æ·¹æ²¡
            partial_text = snapshot.main_text[:5000] + "\n\n...[Middle section omitted for summarization]...\n\n" + snapshot.main_text[-2000:]
            
            abstract = await self._generate_summary(partial_text, ctx.purpose, mode="abstract")
            
            note = f"**Note**: Document is very long ({text_len} chars). Below is an AI generated abstract based on intro/outro, followed by the full raw text."
            final_content = self._format_markdown(snapshot, f"{note}\n\n{abstract}", snapshot.main_text)

        # === 3. å†™å…¥æ–‡ä»¶ ===
        try:
            with open(save_path, "w", encoding="utf-8") as f:
                f.write(final_content)
            
            # === 4. æ›´æ–°çŸ¥è¯†åº“ç´¢å¼• ===
            # è¿™æ˜¯ç»™ Brain æœ€åçœ‹çš„ Manifest
            ctx.knowledge_base.append({
                "type": "page",
                "title": snapshot.title,
                "url": snapshot.url,
                "file_path": filename, # ç›¸å¯¹è·¯å¾„
                "summary_type": summary_type,
                "size_kb": round(text_len / 1024, 1)
            })
            
        except Exception as e:
            self.logger.error(f"Failed to write file {save_path}: {e}")

    # --- è¾…åŠ©å‡½æ•° ---

    def _format_markdown(self, snapshot: PageSnapshot, summary_part: str, raw_part: str) -> str:
        """
        ç»Ÿä¸€çš„ Markdown æ–‡ä»¶æ ¼å¼
        """
        return textwrap.dedent(f"""
        # {snapshot.title}
        
        > Source: {snapshot.url}
        > Captured: {time.strftime("%Y-%m-%d %H:%M:%S")}
        
        ## ğŸ¤– AI Summary / Notes
        {summary_part}
        
        ---
        
        ## ğŸ“„ Original Content
        {raw_part}
        """).strip()

    async def _generate_summary(self, text: str, purpose: str, mode: str = "deep") -> str:
        """
        è°ƒç”¨å°è„‘ç”Ÿæˆæ€»ç»“
        """
        if mode == "deep":
            task_desc = "Create a detailed structured summary (Markdown). Focus on facts, data, and answers relevant to the Research Goal."
        else:
            task_desc = "Create a brief Abstract/Overview (1-2 paragraphs). Explain what this document is about and its potential value."

        prompt = f"""
        You are a Research Assistant.
        Research Goal: "{purpose}"
        
        Task: {task_desc}
        
        Content:
        {text}
        
        Output Markdown only.
        """
        
        try:
            resp = await self.cerebellum.backend.think(messages=[{"role": "user", "content": prompt}])
            return resp.get('reply', '').strip()
        except Exception:
            return "[Error: AI Summary Generation Failed]"

    import re

    async def _filter_relevant_links(self, candidates, one_line_summary, ctx: MissionContext) -> List[str]:
        """
        [Brain] æ‰¹é‡ç­›é€‰é“¾æ¥ã€‚
        è¾“å…¥ï¼šä¸€æ‰¹å€™é€‰å…ƒç´ 
        è¾“å‡ºï¼šå€¼å¾—è®¿é—®çš„ URL åˆ—è¡¨
        ç­–ç•¥ï¼šHard Filter (è§„åˆ™) -> Batch LLM Filter (å°è„‘)
        """
        # 1. è§„åˆ™é¢„æ¸…æ´— (Hard Filter)
        # è¿‡æ»¤æ‰æ˜æ˜¾æ— å…³çš„å¯¼èˆªè¯ï¼ŒèŠ‚çœ Token
        # ä¹Ÿå¯ä»¥è¿‡æ»¤æ‰å·²ç»è®¿é—®è¿‡çš„ (visited)
        clean_candidates = {}
        ignored_keywords = [
            "login", "signin", "sign up", "register", "password", 
            "privacy policy", "terms of use", "contact us", "about us", 
            "customer service", "language", "sitemap", "javascript:", 
            "mailto:", "tel:", "unsubscribe"
        ]
        
        for link, link_text in candidates.items():
            # åŸºç¡€æ ¡éªŒ
            if not link or len(link_text) < 2: continue
            
            # é»‘åå•å…³é”®è¯è¿‡æ»¤
            text_lower = link_text.lower()
            if any(k in text_lower for k in ignored_keywords):
                continue
            
            # å…¨å±€å»é‡è¿‡æ»¤ (å¦‚æœå·²ç»è®¿é—®è¿‡ï¼Œå°±ä¸éœ€è¦å†åˆ¤æ–­äº†)
            if ctx.has_visited(link):
                continue

            clean_candidates[link]=link_text

        if not clean_candidates:
            self.logger.debug(f"No clean links found for {ctx.purpose}")
            return {}

        # 2. åˆ†æ‰¹è°ƒç”¨å°è„‘ (Batch Processing)
        # æœ¬åœ°æ¨¡å‹ä¸Šä¸‹æ–‡æœ‰é™ï¼Œå»ºè®®æ¯æ‰¹ 15-20 ä¸ªé“¾æ¥
        batch_size = 10
        selected_urls = []
        
        # é¢„ç¼–è¯‘æ­£åˆ™ï¼Œæå– http/https å¼€å¤´çš„é“¾æ¥
        # å…è®¸ URL åŒ…å«å¸¸è§å­—ç¬¦ï¼Œé‡åˆ°æ¢è¡Œæˆ–å¼•å·åœæ­¢
        url_pattern = re.compile(r'(https?://[^\s"\'<>]+)')
        candidates_list = list(clean_candidates.items())

        for i in range(0, len(candidates_list), batch_size):
            batch = candidates_list[i : i + batch_size]
            
            # æ„é€ ç»™ LLM çœ‹çš„æ¸…å•
            # æ ¼å¼: - [Link Text] (URL)
            list_str = "\n".join([f"- [{text}] ({url})" for url,text in batch])
            self.logger.debug(f"Processing batch: {list_str}")
            
            # æ„é€ å½“å‰æ‰¹æ¬¡çš„â€œç™½åå•â€ï¼Œç”¨äºéªŒè¯ LLM çš„è¾“å‡º
            # è¿™æ ·å³ä½¿ LLM è¾“å‡ºäº†å¹»è§‰ URLï¼Œä¹Ÿä¼šè¢«è¿™é‡Œæ‹¦ä½
            batch_url_map = {url.strip(): text for url,text in batch}
            
            prompt = f"""
            Mission: Find links relevant to "{ctx.purpose}".
            
            Below is a list of links found on a webpage. 
            This page is about: {one_line_summary}.
            Select ONLY the links that are likely to contain information related to the Mission or worth to explore.
            
            [Candidates]
            {list_str}
            
            [Instructions]
            1. Select links that are likely to contain information related to the Mission. Or may lead to information related to the Mission (destinatioin worth explore).
            2. Ignore links clearly point to non-relavant pages or destinations
            3. æ³¨æ„ï¼Œå¦‚æœæ˜¯ç™¾åº¦ç™¾ç§‘è¿™æ ·çš„ç½‘é¡µï¼Œä¸Šé¢çš„é“¾æ¥å¾ˆå¤šæ˜¯æ— å…³çš„ï¼Œè¦ä»”ç»†ç”„åˆ«ï¼Œåªé€‰æ‹©ç¡®å®šæœ‰å…³çš„
            4. OUTPUT FORMAT: Just list the full URLs of the selected links, one per line.
            """

            try:
                # è°ƒç”¨å°è„‘
                resp = await self.cerebellum.backend.think(messages=[{"role": "user", "content": prompt}])
                raw_reply = resp.get('reply', '')
                self.logger.debug(f"LLM reply: {raw_reply}")
                
                # 3. æ­£åˆ™æå–ä¸éªŒè¯ (Extraction & Validation)
                found_urls = url_pattern.findall(raw_reply)
                
                for raw_url in found_urls:
                    # æ¸…æ´—ï¼šæœ‰äº› LLM å–œæ¬¢åœ¨ URL åé¢åŠ å¥å·æˆ–é€—å·
                    clean_url = raw_url.strip('.,;)]}"\'')
                    
                    # éªŒè¯ï¼šè¿™ä¸ª URL çœŸçš„åœ¨æˆ‘ä»¬çš„è¾“å…¥æ‰¹æ¬¡é‡Œå—ï¼Ÿ
                    # 1. ç²¾ç¡®åŒ¹é…
                    if clean_url in batch_url_map:
                        selected_urls.append(clean_url)
                    else:
                        # 2. å®¹é”™åŒ¹é… (æœ‰æ—¶ LLM ä¼šæˆªæ–­ URL å‚æ•°)
                        # å¦‚æœ batch é‡Œæœ‰ https://a.com/b?id=1ï¼ŒLLM è¾“å‡ºäº† https://a.com/b
                        # æˆ‘ä»¬å°è¯•æ‰¾â€œæœ€ç›¸ä¼¼â€çš„ï¼Œæˆ–è€…ç›´æ¥å¿½ç•¥ã€‚ä¸ºäº†å®‰å…¨ï¼Œè¿™é‡Œåªåšç²¾ç¡®åŒ¹é…æˆ–ç®€å•çš„åŒ…å«åŒ¹é…ã€‚
                        # è€ƒè™‘åˆ° URL å¯èƒ½å¾ˆé•¿ï¼ŒLLM å¯èƒ½ä¼šæŠ„é”™ï¼Œæˆ‘ä»¬å¯ä»¥åå‘æŸ¥ï¼š
                        # çœ‹çœ‹ batch é‡Œæœ‰æ²¡æœ‰å“ªä¸ª URL åŒ…å«äº†è¿™ä¸ª clean_url
                        for original_url in batch_url_map.keys():
                            if clean_url in original_url and len(clean_url) > 15: # é•¿åº¦ä¿æŠ¤é˜²æ­¢åŒ¹é…åˆ° 'http'
                                selected_urls.append(original_url)
                                break
            
            except Exception as e:
                self.logger.error(f"Link filtering batch failed: {e}")
                continue
        self.logger.debug(f"Selected links: {selected_urls}")
        # å»é‡è¿”å›
        return list(set(selected_urls))

    async def _choose_best_interaction(
        self,
        candidates: List[Dict],
        one_line_summary: str,
        ctx: MissionContext
    ) -> Optional[PageElement]:
        """
        [Brain] ä»å€™é€‰æŒ‰é’®ä¸­é€‰æ‹©æœ€å€¼å¾—ç‚¹å‡»çš„ä¸€ä¸ªã€‚
        ä½¿ç”¨ä¸²è¡Œæ·˜æ±°æœºåˆ¶ + ä¸‰çº§ç­›é€‰ç­–ç•¥ï¼š
        1. Immediate (ç«‹å³è®¿é—®): é«˜åº¦å»åˆï¼Œç›´æ¥è¿”å›
        2. Potential (æ½œåœ¨ç›¸å…³): å¯èƒ½ç›¸å…³ï¼Œæ”¾å›é˜Ÿåˆ—å¤´éƒ¨ç»§ç»­ç«äº‰
        3. None (æ— ä»·å€¼): åˆ é™¤ï¼Œç»§ç»­ä¸‹ä¸€ç»„

        Args:
            candidates: List[Dict] æ ¼å¼ï¼Œæ¯ä¸ª Dict æ˜¯ {button_text: PageElement}
        """
        if not candidates:
            return None

        from collections import deque

        BATCH_SIZE = 10  # æ¯æ‰¹è¯„ä¼°çš„æ•°é‡

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼: [(button_text, element), ...]
        # candidates æ˜¯ [{"text1": element1}, {"text2": element2}, ...]
        all_candidates = []
        for candidate_dict in candidates:
            # æ¯ä¸ª dict åªæœ‰ä¸€ä¸ªé”®å€¼å¯¹
            for text, element in candidate_dict.items():
                all_candidates.append((text, element))

        # ä½¿ç”¨ deque æ”¯æŒé«˜æ•ˆçš„å¤´éƒ¨æ“ä½œ
        candidate_deque = deque(all_candidates)

        self.logger.info(f"ğŸ” Sequential filtering started with {len(candidate_deque)} candidates")

        iteration = 0
        while candidate_deque:
            iteration += 1

            # å–å‰ batch_size ä¸ªï¼ˆå¦‚æœä¸è¶³åˆ™å–å…¨éƒ¨ï¼‰
            batch_size = min(BATCH_SIZE, len(candidate_deque))
            batch = [candidate_deque.popleft() for _ in range(batch_size)]

            self.logger.debug(f"  Iter {iteration}: Evaluating {len(batch)} candidates, {len(candidate_deque)} remaining")

            # è¯„ä¼°è¿™æ‰¹
            result = await self._evaluate_batch(batch, one_line_summary, ctx)

            if result["priority"] == "immediate":
                # æ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œç«‹å³è¿”å›
                self.logger.info(f"âš¡ Immediate match found: [{result['text']}] | Reason: {result['reason']}")
                return result["element"]

            elif result["priority"] == "potential":
                # å°† winner æ”¾å›é˜Ÿåˆ—å¤´éƒ¨ï¼Œå‚ä¸ä¸‹ä¸€è½®ç«äº‰
                winner_tuple = (result["text"], result["element"])
                if len(candidate_deque)>0:
                    candidate_deque.appendleft(winner_tuple)
                    self.logger.debug(f"    Potential: [{result['text']}] â†’ Put back to queue front. Queue size: {len(candidate_deque)}")
                else:
                    return result["element"]
            # else: Noneï¼Œè¿™æ‰¹å…¨éƒ¨ä¸¢å¼ƒï¼Œç»§ç»­ä¸‹ä¸€è½®

        # é˜Ÿåˆ—ä¸ºç©ºï¼Œæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰ä»·å€¼çš„æŒ‰é’®
        self.logger.info("âŒ Queue exhausted. No worthy buttons found.")
        return None

    async def _evaluate_batch(
        self,
        batch: List[tuple],
        one_line_summary: str,
        ctx: MissionContext
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°ä¸€æ‰¹å€™é€‰æŒ‰é’®ï¼Œè¿”å›æœ€ä½³é€‰æ‹©ï¼ˆå¸¦ä¼˜å…ˆçº§ï¼‰ã€‚

        ä¸‰çº§ç­›é€‰ç­–ç•¥ï¼š
        1. IMMEDIATE: é«˜åº¦å»åˆï¼Œåº”è¯¥ç«‹å³è®¿é—®ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
        2. POTENTIAL: å¯èƒ½ç›¸å…³ï¼Œå€¼å¾—è€ƒè™‘ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼‰
        3. NONE: éƒ½ä¸ç›¸å…³ï¼ˆæœ€ä½ä¼˜å…ˆçº§ï¼‰

        Args:
            batch: [(button_text, element), ...] æ ¼å¼çš„å€™é€‰åˆ—è¡¨
            one_line_summary: å½“å‰é¡µé¢æ‘˜è¦
            ctx: ä»»åŠ¡ä¸Šä¸‹æ–‡

        Returns:
            {
                "priority": "immediate" | "potential" | "none",
                "text": str,
                "element": PageElement,
                "reason": str
            }
            å¦‚æœ priority == "none"ï¼Œtext å’Œ element ä¸º None
        """
        if not batch:
            return {"priority": "none", "text": None, "element": None, "reason": "Empty batch"}

        # æ„é€ é€‰é¡¹å­—ç¬¦ä¸²
        options_str = ""
        for idx, (text, element) in enumerate(batch):
            options_str += f"{idx + 1}. [{text}]\n"

        # æ·»åŠ "å¼ƒæƒ"é€‰é¡¹
        options_str += "0. [None of these are useful]"

        # æ„é€  Prompt
        prompt = f"""
You are a Research Crawler evaluating buttons for a web crawling mission.

[Mission]
"{ctx.purpose}"

[Current Page Context]
{one_line_summary}

[Task]
Evaluate the buttons below and categorize your choice into THREE levels:

**LEVEL 1 - IMMEDIATE (åº”ç«‹å³è®¿é—®)**
- Criteria: æŒ‰é’®æè¿°ä¸ Mission ç›®æ ‡é«˜åº¦åŒ¹é…ï¼Œæ˜ç¡®æŒ‡å‘ä½ éœ€è¦çš„æ ¸å¿ƒä¿¡æ¯
- Examples: "Python Tutorial", "Machine Learning Guide", "API Documentation"
- Action: é€‰æ‹©è¯¥æŒ‰é’®ï¼Œè¿”å› priority="immediate"

**LEVEL 2 - POTENTIAL (å¯èƒ½ç›¸å…³)**
- Criteria: æŒ‰é’®å¯èƒ½å¯¼å‘ç›¸å…³å†…å®¹ï¼Œä½†ä¸å¤Ÿæ˜ç¡®
- Examples: "Learn More", "Details", "Next Page", "View Resources"
- Action: é€‰æ‹©æœ€ç›¸å…³çš„ä¸€ä¸ªæŒ‰é’®ï¼Œè¿”å› priority="potential"

**LEVEL 3 - NONE (éƒ½ä¸ç›¸å…³)**
- Criteria: æ‰€æœ‰æŒ‰é’®éƒ½ä¸ Mission æ— å…³ï¼Œæˆ–æ˜¯çº¯å¯¼èˆª/ç¤¾äº¤åŠŸèƒ½
- Examples: "Share", "Login", "Home", "Contact Us", generic navigation
- Action: è¿”å› choice_id=0, priority="none"

[Options]
{options_str}

[Output Requirement]
Return JSON ONLY. Format:
{{
    "choice_id": <number 0-{len(batch)}>,
    "priority": "immediate" | "potential" | "none",
    "reason": "short explanation (one line)"
}}

IMPORTANT:
- If choice_id is 0, set priority="none"
- If choice_id is 1-{len(batch)}, set priority based on your evaluation
"""

        try:
            # è°ƒç”¨å°è„‘
            resp = await self.cerebellum.backend.think(messages=[{"role": "user", "content": prompt}])
            raw_reason = resp.get('reasoning',''   )
            raw_reply = resp.get('reply', '')
            self.logger.debug(f"Reasong: {raw_reason}")
            self.logger.debug(f"Reply: {raw_reply}")

            # è§£æç»“æœ
            json_str = raw_reply.replace("```json", "").replace("```", "").strip()
            result = json.loads(json_str)

            choice_id = int(result.get("choice_id", 0))
            priority = result.get("priority", "none").lower()
            reason = result.get("reason", "")

            # éªŒè¯ priority å€¼
            if priority not in ["immediate", "potential", "none"]:
                priority = "none"

            if choice_id == 0 or priority == "none":
                self.logger.debug(f"    No worthy button. Reason: {reason}")
                return {"priority": "none", "text": None, "element": None, "reason": reason}

            # è½¬æ¢ä¸º 0-based index
            selected_index = choice_id - 1

            if 0 <= selected_index < len(batch):
                selected_text, selected_element = batch[selected_index]
                return {
                    "priority": priority,
                    "text": selected_text,
                    "element": selected_element,
                    "reason": reason
                }
            else:
                self.logger.warning(f"    Invalid choice_id: {choice_id}")
                return {"priority": "none", "text": None, "element": None, "reason": "Invalid choice"}

        except Exception as e:
            self.logger.exception(f"    Batch evaluation failed: {e}")
            return {"priority": "none", "text": None, "element": None, "reason": f"Error: {e}"}

    def _generate_final_report(self, ctx: MissionContext) -> str:
        return f"Mission Complete. Found {len(ctx.knowledge_base)} items."