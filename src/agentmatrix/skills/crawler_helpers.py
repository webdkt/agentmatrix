"""
çˆ¬è™«æŠ€èƒ½çš„å…¬å…±è¾…åŠ©æ–¹æ³•

æä¾›é“¾æ¥ç­›é€‰ã€æŒ‰é’®é€‰æ‹©ç­‰ LLM å†³ç­–åŠŸèƒ½ã€‚
"""

import json
import re
import asyncio
from collections import deque
from typing import Dict, List, Optional, Any


class CrawlerHelperMixin:
    """
    çˆ¬è™«æŠ€èƒ½çš„å…¬å…±è¾…åŠ©æ–¹æ³• Mixin

    ä¾èµ–ï¼š
    - self.cerebellum.backend.think() - LLM è°ƒç”¨
    - self.logger - æ—¥å¿—è®°å½•
    """
    


    async def _filter_relevant_links(
        self,
        candidates: Dict[str, str],
        page_summary: str,
        ctx,
        prompt_template: str = None
    ) -> List[str]:
        """
        [Brain] æ‰¹é‡ç­›é€‰é“¾æ¥ï¼ˆç»Ÿä¸€å®ç°ï¼‰

        Args:
            candidates: å€™é€‰é“¾æ¥å­—å…¸ {url: link_text}
            page_summary: å½“å‰é¡µé¢æ‘˜è¦
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆMissionContext æˆ– WebSearcherContextï¼‰
            prompt_template: å¯é€‰çš„è‡ªå®šä¹‰ promptï¼ˆç”¨äºç‰¹æ®Šéœ€æ±‚ï¼‰

        Returns:
            ç­›é€‰åçš„ URL åˆ—è¡¨
        """
        # 1. è§„åˆ™é¢„è¿‡æ»¤
        ignored_keywords = [
            "login", "signin", "sign up", "register", "password",
            "privacy policy", "terms of use", "contact us", "about us",
            "customer service", "language", "sitemap", "javascript:",
            "mailto:", "tel:", "unsubscribe"
        ]

        clean_candidates = {}
        for link, link_text in candidates.items():
            if not link or len(link_text) < 2:
                continue
            text_lower = link_text.lower()
            if any(k in text_lower for k in ignored_keywords):
                continue
            clean_candidates[link] = link_text

        if not clean_candidates:
            self.logger.debug(f"No clean links found for {ctx.purpose}")
            return []

        # 2. åˆ†æ‰¹ LLM è¿‡æ»¤
        batch_size = 10
        selected_urls = []
        url_pattern = re.compile(r'(https?://[^\s"\'<>]+)')
        candidates_list = list(clean_candidates.items())

        for i in range(0, len(candidates_list), batch_size):
            batch = candidates_list[i:i + batch_size]
            list_str = "\n".join([f"- [{text}] ({url})" for url, text in batch])
            batch_url_map = {url.strip(): text for url, text in batch}

            # ä½¿ç”¨è‡ªå®šä¹‰æˆ–é»˜è®¤ prompt
            if prompt_template:
                prompt = prompt_template.format(
                    purpose=ctx.purpose,
                    page_summary=page_summary,
                    list_str=list_str
                )
            else:
                # é»˜è®¤ prompt
                prompt = f"""
                Mission: Find links relevant to "{ctx.purpose}".

                Below is a list of links found on a webpage.
                This page is about: {page_summary}.
                Select ONLY the links that are likely to contain information related to the Mission or worth to explore.

                [Candidates]
                {list_str}

                [Instructions]
                1. Select links that are likely to contain information related to the Mission. Or may lead to information related to the Mission (destination worth explore).
                2. Ignore links clearly point to non-relevant pages or destinations
                3. æ³¨æ„ï¼Œå¦‚æœæ˜¯ç™¾åº¦ç™¾ç§‘è¿™æ ·çš„ç½‘é¡µï¼Œä¸Šé¢çš„é“¾æ¥å¾ˆå¤šæ˜¯æ— å…³çš„ï¼Œè¦ä»”ç»†ç”„åˆ«ï¼Œåªé€‰æ‹©ç¡®å®šæœ‰å…³çš„
                4. OUTPUT FORMAT: Just list the full URLs of the selected links, one per line.
                """

            try:
                # è°ƒç”¨å°è„‘
                resp = await self.cerebellum.backend.think(
                    messages=[{"role": "user", "content": prompt}]
                )
                raw_reply = resp.get('reply', '')
                self.logger.debug(f"LLM reply: {raw_reply}")

                # 3. æ­£åˆ™æå–ä¸éªŒè¯
                found_urls = url_pattern.findall(raw_reply)
                for raw_url in found_urls:
                    clean_url = raw_url.strip('.,;)]}"\'')

                    if clean_url in batch_url_map:
                        selected_urls.append(clean_url)
                    else:
                        # å®¹é”™åŒ¹é…
                        for original_url in batch_url_map.keys():
                            if clean_url in original_url and len(clean_url) > 15:
                                selected_urls.append(original_url)
                                break

            except Exception as e:
                self.logger.error(f"Link filtering batch failed: {e}")
                continue

        self.logger.debug(f"Selected links: {selected_urls}")
        return list(set(selected_urls))

    async def _choose_best_interaction(
        self,
        candidates: List[Dict],
        page_summary: str,
        ctx,
        prompt_template: str = None
    ) -> Optional:
        """
        [Brain] é€‰æ‹©æœ€ä½³æŒ‰é’®ç‚¹å‡»ï¼ˆç»Ÿä¸€å®ç°ï¼‰

        ä½¿ç”¨ä¸²è¡Œæ·˜æ±°æœºåˆ¶ + ä¸‰çº§ç­›é€‰ç­–ç•¥ï¼š
        1. Immediate (ç«‹å³è®¿é—®): é«˜åº¦å»åˆï¼Œç›´æ¥è¿”å›
        2. Potential (æ½œåœ¨ç›¸å…³): å¯èƒ½ç›¸å…³ï¼Œæ”¾å›é˜Ÿåˆ—å¤´éƒ¨ç»§ç»­ç«äº‰
        3. None (æ— ä»·å€¼): åˆ é™¤ï¼Œç»§ç»­ä¸‹ä¸€ç»„

        Args:
            candidates: List[Dict] æ ¼å¼ï¼Œæ¯ä¸ª Dict æ˜¯ {button_text: PageElement}
            page_summary: å½“å‰é¡µé¢æ‘˜è¦
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆMissionContext æˆ– WebSearcherContextï¼‰
            prompt_template: å¯é€‰çš„è‡ªå®šä¹‰ prompt æ¨¡æ¿

        Returns:
            é€‰ä¸­çš„ PageElementï¼Œå¦‚æœæ²¡æœ‰åˆé€‚çš„åˆ™è¿”å› None
        """
        if not candidates:
            return None

        BATCH_SIZE = 10

        # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼: [(button_text, element), ...]
        all_candidates = []
        for candidate_dict in candidates:
            for text, element in candidate_dict.items():
                all_candidates.append((text, element))

        # ä½¿ç”¨ deque æ”¯æŒé«˜æ•ˆçš„å¤´éƒ¨æ“ä½œ
        candidate_deque = deque(all_candidates)

        while candidate_deque:
            # å–å‰ batch_size ä¸ªï¼ˆå¦‚æœä¸è¶³åˆ™å–å…¨éƒ¨ï¼‰
            batch_size = min(BATCH_SIZE, len(candidate_deque))
            batch = [candidate_deque.popleft() for _ in range(batch_size)]

            # è¯„ä¼°è¿™æ‰¹
            if prompt_template:
                result = await self._evaluate_button_batch(
                    batch, page_summary, ctx, prompt_template
                )
            else:
                result = await self._evaluate_button_batch(
                    batch, page_summary, ctx
                )

            if result["priority"] == "immediate":
                # æ‰¾åˆ°æœ€ä½³åŒ¹é…ï¼Œç«‹å³è¿”å›
                self.logger.info(
                    f"âš¡ Immediate match found: [{result['text']}] | "
                    f"Reason: {result['reason']}"
                )
                return result["element"]

            elif result["priority"] == "potential":
                # å°† winner æ”¾å›é˜Ÿåˆ—å¤´éƒ¨ï¼Œå‚ä¸ä¸‹ä¸€è½®ç«äº‰
                winner_tuple = (result["text"], result["element"])
                if len(candidate_deque) > 0:
                    candidate_deque.appendleft(winner_tuple)
                    self.logger.debug(
                        f"    Potential: [{result['text']}] â†’ Put back to queue front. "
                        f"Queue size: {len(candidate_deque)}"
                    )
                else:
                    return result["element"]
            # else: Noneï¼Œè¿™æ‰¹å…¨éƒ¨ä¸¢å¼ƒï¼Œç»§ç»­ä¸‹ä¸€è½®

        return None

    async def _evaluate_button_batch(
        self,
        batch: List[tuple],
        page_summary: str,
        ctx,
        prompt_template: str = None
    ) -> Dict[str, Any]:
        """
        è¯„ä¼°ä¸€æ‰¹æŒ‰é’®ï¼ˆç»Ÿä¸€å®ç°ï¼‰

        Args:
            batch: [(button_text, element), ...]
            page_summary: é¡µé¢æ‘˜è¦
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡
            prompt_template: å¯é€‰çš„è‡ªå®šä¹‰ prompt æ¨¡æ¿

        Returns:
            {
                "priority": "immediate" | "potential" | "none",
                "text": str,
                "element": PageElement,
                "reason": str
            }
        """
        if not batch:
            return {"priority": "none", "text": None, "element": None, "reason": "Empty batch"}

        options_str = ""
        for idx, (text, element) in enumerate(batch):
            options_str += f"{idx + 1}. [{text}]\n"
        options_str += "0. [None of these are useful]"

        # ä½¿ç”¨è‡ªå®šä¹‰æˆ–é»˜è®¤ prompt
        if prompt_template:
            prompt = prompt_template.format(
                purpose=ctx.purpose,
                page_summary=page_summary,
                options_str=options_str,
                batch_size=len(batch)
            )
        else:
            # é»˜è®¤ promptï¼ˆå– data_crawler çš„ç‰ˆæœ¬ï¼Œæ›´è¯¦ç»†ï¼‰
            prompt = f"""
            You are evaluating buttons on a webpage to see if it can help with your research topic:
            [Research Topic]
                 {ctx.purpose}

            [Page Context]
            {page_summary}

            [Task]
            Categorize your choice into THREE levels:

            **LEVEL 1 - IMMEDIATE** (åº”ç«‹å³è®¿é—®)
            - Button clearly leads to information that achieves the purpose

            **LEVEL 2 - POTENTIAL** (å¯èƒ½ç›¸å…³)
            - Button might lead to relevant information
            - Examples: "Learn More", "Details", "Next", "View Resources"

            **LEVEL 3 - NONE** (éƒ½ä¸ç›¸å…³)
            - Buttons unrelated to the purpose
            - Examples: "Share", "Login", "Home", "Contact"

            [Options]
            {options_str}

            [Output Format]
            JSON:
            {{
                "choice_id": <number 0-{len(batch)}>,
                "priority": "immediate" | "potential" | "none",
                "reason": "short explanation"
            }}
            """

        try:
            resp = await self.cerebellum.backend.think(
                messages=[{"role": "user", "content": prompt}]
            )
            raw_reply = resp.get('reply', '')

            # æå– JSONï¼ˆå…¼å®¹å„ç§æ ¼å¼ï¼‰
            json_str = raw_reply.replace("```json", "").replace("```", "").strip()
            result = json.loads(json_str)

            choice_id = int(result.get("choice_id", 0))
            priority = result.get("priority", "none").lower()
            reason = result.get("reason", "")

            if priority not in ["immediate", "potential", "none"]:
                priority = "none"

            if choice_id == 0 or priority == "none":
                return {"priority": "none", "text": None, "element": None, "reason": reason}

            selected_index = choice_id - 1

            if 0 <= selected_index < len(batch):
                selected_text, selected_element = batch[selected_index]
                return {
                    "priority": priority,
                    "text": selected_text,
                    "element": selected_element,
                    "reason": reason
                }
            else:
                return {"priority": "none", "text": None, "element": None, "reason": "Invalid choice"}

        except Exception as e:
            self.logger.exception(f"Batch evaluation failed: {e}")
            return {"priority": "none", "text": None, "element": None, "reason": f"Error: {e}"}

    async def _get_full_page_markdown(self, tab, ctx) -> str:
        """
        è·å–å®Œæ•´é¡µé¢çš„ Markdownï¼Œè‡ªåŠ¨è¯†åˆ« HTML/PDF

        Args:
            tab: æµè§ˆå™¨æ ‡ç­¾é¡µå¥æŸ„
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆå¯é€‰ï¼Œç”¨äºä¸´æ—¶æ–‡ä»¶ä¿å­˜ï¼‰

        Returns:
            str: Markdown æ ¼å¼çš„é¡µé¢å†…å®¹
        """
        from ..core.browser.browser_adapter import PageType

        content_type = await self.browser.analyze_page_type(tab)

        if content_type == PageType.STATIC_ASSET:
            return await self._pdf_to_full_markdown(tab, ctx)
        else:
            return await self._html_to_full_markdown(tab)

    async def _html_to_full_markdown(self, tab) -> str:
        """
        å°† HTML é¡µé¢è½¬æ¢ä¸ºå®Œæ•´ Markdown

        Args:
            tab: æµè§ˆå™¨æ ‡ç­¾é¡µå¥æŸ„

        Returns:
            str: Markdown æ ¼å¼çš„é¡µé¢å†…å®¹
        """
        import trafilatura

        raw_html = tab.html
        url = self.browser.get_tab_url(tab)

        # ä½¿ç”¨ trafilatura æå–å®Œæ•´ Markdown
        markdown = trafilatura.extract(
            raw_html,
            include_links=True,
            include_formatting=True,
            output_format='markdown',
            url=url
        )

        # é™çº§æ–¹æ¡ˆï¼šå¦‚æœå¤±è´¥ï¼Œå°è¯•åªæå–æ–‡æœ¬ï¼ˆä¸å«é“¾æ¥å’Œæ ¼å¼ï¼‰
        if not markdown or len(markdown) < 50:
            markdown = trafilatura.extract(
                raw_html,
                include_links=False,
                include_formatting=False,
                output_format='markdown',
                only_with_text=True
            )

        return markdown or ""

    async def _pdf_to_full_markdown(self, tab, ctx) -> str:
        """
        å°† PDF è½¬æ¢ä¸ºå®Œæ•´ Markdown

        Args:
            tab: æµè§ˆå™¨æ ‡ç­¾é¡µå¥æŸ„
            ctx: ä¸Šä¸‹æ–‡å¯¹è±¡ï¼ˆå¯é€‰ï¼Œç”¨äºä¸´æ—¶æ–‡ä»¶ä¿å­˜ï¼‰

        Returns:
            str: Markdown æ ¼å¼çš„ PDF å†…å®¹
        """
        # ä¸‹è½½ PDF åˆ°æœ¬åœ°
        pdf_path = await self.browser.save_static_asset(tab)

        # è°ƒç”¨ PDF è½¬æ¢ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ï¼‰
        markdown = await asyncio.to_thread(
            self._convert_pdf_to_markdown_text,
            pdf_path
        )

        # å¯é€‰ï¼šä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼ˆå¦‚æœ ctx æ”¯æŒï¼‰
        if hasattr(ctx, 'temp_file_dir') and ctx.temp_file_dir:
            self._save_temp_markdown(markdown, pdf_path, ctx.temp_file_dir)

        return markdown

    def _convert_pdf_to_markdown_text(self, pdf_path: str) -> str:
        """
        å°† PDF æ–‡ä»¶è½¬æ¢ä¸º Markdown æ–‡æœ¬ï¼ˆæ ¸å¿ƒå®ç°ï¼‰

        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„

        Returns:
            str: Markdown æ ¼å¼çš„æ–‡æœ¬

        Raises:
            Exception: PDF è½¬æ¢å¤±è´¥
        """
        from marker.converters.pdf import PdfConverter
        from marker.models import create_model_dict
        from marker.output import text_from_rendered
        import fitz

        try:
            # è·å– PDF æ€»é¡µæ•°
            with fitz.open(pdf_path) as doc:
                total_pages = len(doc)

            self.logger.debug(f"PDFæ€»é¡µæ•°: {total_pages}")

            # åˆå§‹åŒ– marker æ¨¡å‹
            self.logger.debug("åŠ è½½ marker æ¨¡å‹...")
            converter = PdfConverter(
                artifact_dict=create_model_dict(),
            )

            # æ‰§è¡Œè½¬æ¢
            self.logger.debug("æ­£åœ¨è½¬æ¢ PDF åˆ° Markdown...")
            rendered = converter(pdf_path)

            # ä»æ¸²æŸ“ç»“æœä¸­æå–æ–‡æœ¬
            text, _, images = text_from_rendered(rendered)

            self.logger.debug(f"è½¬æ¢å®Œæˆ! å…± {len(text)} ä¸ªå­—ç¬¦")

            return text

        except Exception as e:
            self.logger.error(f"PDF è½¬æ¢å¤±è´¥: {e}")
            raise

    def _save_temp_markdown(self, markdown: str, pdf_path: str, temp_dir: str):
        """
        ä¿å­˜ä¸´æ—¶ Markdown æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰

        Args:
            markdown: Markdown æ–‡æœ¬
            pdf_path: åŸå§‹ PDF è·¯å¾„
            temp_dir: ä¸´æ—¶ç›®å½•
        """
        import os
        from slugify import slugify

        os.makedirs(temp_dir, exist_ok=True)
        filename = slugify(f"pdf_{os.path.basename(pdf_path)}") + ".md"
        temp_path = os.path.join(temp_dir, filename)

        with open(temp_path, "w", encoding="utf-8") as f:
            f.write(markdown)

        self.logger.info(f"ğŸ“„ ä¿å­˜ä¸´æ—¶ Markdown: {temp_path}")
